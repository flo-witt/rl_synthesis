{"best_episode_return": "53.51259", "best_return": "5.1512585", "goal_value": "10.0", "returns_episodic": "[47.833332, 53.51259]", "returns": "[4.5833335, 5.1512585]", "reach_probs": "[1.0, 1.0]", "trap_reach_probs": "[0.0, 0.0]", "best_reach_prob": "1.0", "losses": "[77.38937, 8.079308, 12.476335, 8.706857, 10.8509035, 15.145871, 4.497373, 12.9553385, 10.445496, 3.7949755, 10.596545]", "each_episode_variance": "[3.65842, 4.340185]", "each_episode_virtual_variance": "[365.842, 434.0185]", "combined_variance": "[442.66882, 525.16235]", "num_episodes": "[4608, 4608]", "paynt_bounds": "[]", "last_from_interpretation": "False", "extracted_fsc_episode_return": "-1.0", "extracted_fsc_return": "-1.0", "extracted_fsc_reach_prob": "-1.0", "extracted_fsc_variance": "-1.0", "extracted_fsc_num_episodes": "-1", "extracted_fsc_virtual_variance": "-1.0", "extracted_fsc_combined_variance": "-1.0", "artificial_reward_means": "[]", "artificial_reward_stds": "[]", "average_episode_length": "[68.88888888888889, 68.88888888888889]", "counted_episodes": "[4608, 4608]", "discounted_rewards": "[39.40845, 44.123035]", "new_pomdp_iteration_numbers": "[2]", "evaluation_time": NaN, "split_iteration": -1}