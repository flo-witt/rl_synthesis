{"best_episode_return": "151.95117", "best_return": "14.995117", "goal_value": "10.0", "returns_episodic": "[138.15234, 151.95117]", "returns": "[13.615234, 14.995117]", "reach_probs": "[1.0, 1.0]", "trap_reach_probs": "[0.0, 0.0]", "best_reach_prob": "1.0", "losses": "[38.06935, 5.0917983, 8.399613, 4.4078636, 6.0393333, 9.887505, 10.207091, 6.888837, 4.4918246, 7.7805505, 10.999975]", "each_episode_variance": "[4.135158, 2.8993897]", "each_episode_virtual_variance": "[413.51593, 289.9391]", "combined_variance": "[500.3542, 350.82623]", "num_episodes": "[1024, 1024]", "paynt_bounds": "[]", "last_from_interpretation": "False", "extracted_fsc_episode_return": "-1.0", "extracted_fsc_return": "-1.0", "extracted_fsc_reach_prob": "-1.0", "extracted_fsc_variance": "-1.0", "extracted_fsc_num_episodes": "-1", "extracted_fsc_virtual_variance": "-1.0", "extracted_fsc_combined_variance": "-1.0", "artificial_reward_means": "[]", "artificial_reward_stds": "[]", "average_episode_length": "[284.5, 284.5]", "counted_episodes": "[1024, 1024]", "discounted_rewards": "[74.21486, 82.09213]", "new_pomdp_iteration_numbers": "[2]", "evaluation_time": NaN, "split_iteration": -1}